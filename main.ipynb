{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique run id based on current time\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "os.makedirs('runs', exist_ok=True)\n",
    "RUN_ID = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "conflicts = [run_id for run_id in os.listdir('runs') if run_id.startswith(RUN_ID)]\n",
    "if conflicts:\n",
    "    RUN_ID += f'_{len(conflicts)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Kaggle API\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "KAGGLE_SECRETS_PATH = 'secrets/kaggle.json'\n",
    "\n",
    "if os.path.exists(KAGGLE_SECRETS_PATH):\n",
    "    with open(KAGGLE_SECRETS_PATH) as f:\n",
    "        secrets = json.load(f)\n",
    "        os.environ['KAGGLE_USERNAME'] = secrets['username']\n",
    "        os.environ['KAGGLE_KEY'] = secrets['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "import kaggle\n",
    "\n",
    "\n",
    "KAGGLE_DATASET = 'gpiosenka/cards-image-datasetclassification'\n",
    "kaggle.api.dataset_download_files(KAGGLE_DATASET, path='raw_data', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to 4 classes\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "\n",
    "if os.path.exists('data'):\n",
    "    shutil.rmtree('data')\n",
    "os.makedirs('data')\n",
    "\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    data_map = {'hearts': [], 'diamonds': [], 'clubs': [], 'spades': []}\n",
    "\n",
    "    for cls in tqdm(os.listdir(f'raw_data/{split}'), desc=split):\n",
    "        new_cls = cls.split()[-1]\n",
    "        if new_cls in data_map:\n",
    "            data_map[new_cls].extend([f'raw_data/{split}/{cls}/{x}' for x in os.listdir(f'raw_data/{split}/{cls}') if x.endswith('.jpg')])\n",
    "\n",
    "    os.makedirs(f'data/{split}')\n",
    "    for cls in tqdm(data_map, desc=split):\n",
    "        os.makedirs(f'data/{split}/{cls}')\n",
    "        for i, img in enumerate(data_map[cls]):\n",
    "            shutil.copy(img, f'data/{split}/{cls}/{cls}.{i}.jpg')\n",
    "\n",
    "shutil.rmtree('raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i, cls in enumerate(['hearts', 'diamonds', 'clubs', 'spades']):\n",
    "    for j in range(4):\n",
    "        img = mpimg.imread(f'data/train/{cls}/{cls}.{random.randint(0, 100)}.jpg')\n",
    "        ax[i, j].imshow(img)\n",
    "        ax[i, j].axis('off')\n",
    "        ax[i, j].set_title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Random Augmentation only for training data\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical', \n",
    "    # Shuffle only for training data\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    'data/valid',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model with 4 class output\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "FEATURE_EXTRACTOR = 'https://www.kaggle.com/models/google/mobilenet-v1/frameworks/TensorFlow2/variations/025-224-feature-vector/versions/2'\n",
    "feature_extractor = hub.KerasLayer(FEATURE_EXTRACTOR, input_shape=(224, 224, 3))\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback with learning rate\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class LRTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir, **kwargs):\n",
    "        super().__init__(log_dir=log_dir, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs.update({'lr': K.eval(self.model.optimizer.lr)})\n",
    "        super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train last layer first\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard_dir = f'runs/{RUN_ID}/tensorboard'\n",
    "callbacks = [\n",
    "    LRTensorBoard(tensorboard_dir),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history_tl = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks + [tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1, min_lr=1e-10)],\n",
    "    epochs=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze feature extractor\n",
    "\n",
    "feature_extractor.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train whole model \n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks + [tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1)],\n",
    "    initial_epoch=len(history_tl.epoch),\n",
    "    epochs=len(history_tl.epoch) + 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge history and plot\n",
    "\n",
    "acc = history_tl.history['accuracy'] + history_ft.history['accuracy']\n",
    "val_acc = history_tl.history['val_accuracy'] + history_ft.history['val_accuracy']\n",
    "loss = history_tl.history['loss'] + history_ft.history['loss']\n",
    "val_loss = history_tl.history['val_loss'] + history_ft.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([len(history_tl.epoch)-1, len(history_tl.epoch)-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([len(history_tl.epoch)-1,len(history_tl.epoch)-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the TensorFlow SavedModel format\n",
    "\n",
    "saved_model_path = f'runs/{RUN_ID}/saved_model'\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_model_path = f'runs/{RUN_ID}/js_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow JS format\n",
    "\n",
    "! tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model --signature_name=serving_default {saved_model_path} {js_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bless the model, copy it to the 'webapp/blessed_model' directory (run only if the model is good)\n",
    "import shutil\n",
    "\n",
    "blessed_model_path = 'webapp/blessed_model'\n",
    "\n",
    "if os.path.exists(blessed_model_path):\n",
    "    shutil.rmtree(blessed_model_path)\n",
    "shutil.copytree(js_model_path, blessed_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobilenet-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
